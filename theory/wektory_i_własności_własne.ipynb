{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teoria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do czego to potrzebne?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wektorów i wartości własnych możemy użyć na przykład do redukcji wymiarowości, na ich podstawie oceniając istotność zmiennych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przekształcenia liniowe (linear transformation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Endomorfizmem liniowym (rodzaj przekształcenia liniowego) jest funkcja $f(\\textbf{w})$ operująca na wektorze kolumnowym długości $n$ postaci$$f(\\textbf{w})=A\\textbf{w},$$ gdzie $A$ jest macierzą kwadratową rozmiaru $n\\times n$.\n",
    "\n",
    "Dla $n=2$ endomorfizm liniowy jest zdefiniowany jako\n",
    "\n",
    "![](../img/2023-03-26-20-14-09.png)\n",
    "\n",
    "Jeżeli każdy punkt na obrazie potraktujemy jako wektor $[x,y]$, możemy zobrazować jak działa przykładowy endomorfizm liniowy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../img/2023-03-26-19-17-31.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../img/2023-03-26-19-21-14.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../img/2023-03-26-19-21-45.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wektory własne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wektor własny wskazuje kierunek skalowania/rotacji jaki wykonuje przekształcenie liniowe\n",
    "$$f(\\textbf{w})=A\\textbf{w},$$\n",
    "Gdzie wzor powyżej opisuje konkretne przekształcenie (przemnożenie wektora W przez macierz przekształceń A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../img/2023-03-26-19-24-22.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natomiast **wartością własną** i związanym z nią **wektorem własnym** nazywamy wartość $\\lambda$ i wektor $\\mathbf{w}_0$ spełniające warunek$$f(\\mathbf{w}_0)=\\lambda \\mathbf{w_0}$$Gdzie w0 opisuje wektor który określa kierunek w jakim zwrócony był wektor z któego wyznaczono wektor własny.\n",
    "```\n",
    "Wektor, który po przeskalowaniu (przemnożenie prez WARTOŚĆ WŁASNĄ) wskazuje ten sam kierunek co oryginalny wektor, jest jego wektorem własnym."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### W pythonie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([25.59639374, -0.52098034,  2.9245866 ]),\n",
       " array([[-0.13957085, -0.84384918, -0.21345016],\n",
       "        [-0.30183948,  0.53152606, -0.87052838],\n",
       "        [-0.9430869 ,  0.0734753 ,  0.44341782]]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "A = np.array([[ 1, 2, 3], [ 4, 5, 6], [ 7, 8, 22]])\n",
    "\n",
    "wartosci_wlasne, wektory_wlasne = np.linalg.eig(A)\n",
    "wartosci_wlasne, wektory_wlasne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Więcej informacji:\n",
    "- https://www.kowalskimateusz.pl/wektory-i-wartosci-wlasne-eigenvalues-and-eigenvectors/ (Stąd m.in zaczerpnięto grafikę wykresu)\n",
    "- https://www.youtube.com/watch?v=qUeud6DvOWI (Artykul powyzej w wersji video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Przykładowe użycie w DataScience (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wstęp do PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykorzystanie do redukcji wymiarowości zbioru danych (Używane w algorytmie PCA - Princial component analysis = Analiza głównych składowych):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Co robi PCA (bardzo ogólnie i skrótowo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bierze duża liczbę zmiennych (np. 50) i kompresuje je do małej (2) z zachowaniem możliwie jak największej wartości opisującej \n",
    "\n",
    "=============================================================================================================\n",
    "\n",
    "KIEDYŚ PCA było używane do kompresji danych i przyśpieszania obliczeń, ale to traci na popularności. Cytat Andrew Ng: \n",
    "\n",
    "\"But it turns out with modern machine learning algorithms, algorithms like deep learning, this doesn't actually hold that much,\n",
    "and is much more common to just take the high-dimensional dataset, and feed it into say your neural network rather than run PCA because PCA has some computational cost as well.\n",
    "\n",
    "You may hear about this in some of the other research papers, but I don't really see this done much anymore.\n",
    "But the most common thing that I use PCA for today is visualization and then I find it very useful to reduce the dimensional data to visualize it.\"\n",
    "\n",
    "=============================================================================================================\n",
    "\n",
    "(Grafika z CURSERY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../img/2023-03-27-00-36-44.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- na Z1 mogą się składać np. featury opisujące wielkość kraju (Liczba kilometrów, liczba miast, liczba ludzi, ...)\n",
    "- na Z2 mogą się składać np. featury opisujące jakość życia każdego obywatela (przychód na obywatela, ilosc mieszkań na człowieka, ...)\n",
    "\n",
    "Ogólnie grupowane są podobne zmienne i to pozwala wizualizować wielowymiarowe dane w sposób interpretowalny przez człowieka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potem na podstawie macierzy wariancji wyznaczana jest taka oś Z (principal component) która będzie miała maksymalną wariancję \n",
    "\n",
    " (Xy rzutowane na tą oś będą jak najmniej na siebie nachodzić, odstępy między nimi będą największe)\n",
    " \n",
    "![](../img/2023-03-27-00-41-34.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do konwersji feature'ów należy:\n",
    "- Znaleźc linię która najlepiej rozdziela Xy\n",
    "- Znajdź wektor o długości 1 który leży na tej linii\n",
    "- Wylicz dot-product starych fature'ów oraz tego wektora\n",
    "\n",
    "Kolejne linie (po wyznaczeniu pierwszej wg wariancji) dobieramy pod kądem 90 stopni do poprzednich"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przykład zastosowania macierzy kowariancji / wektorów własncyh / wartości własncyh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Wczytanie jakichkolwiek danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal_Length</th>\n",
       "      <th>Sepal_Width</th>\n",
       "      <th>Petal_Length</th>\n",
       "      <th>Petal_Width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sepal_Length  Sepal_Width  Petal_Length  Petal_Width\n",
       "0             5.1          3.5           1.4          0.2\n",
       "1             4.9          3.0           1.4          0.2\n",
       "2             4.7          3.2           1.3          0.2\n",
       "3             4.6          3.1           1.5          0.2\n",
       "4             5.0          3.6           1.4          0.2\n",
       "..            ...          ...           ...          ...\n",
       "145           6.7          3.0           5.2          2.3\n",
       "146           6.3          2.5           5.0          1.9\n",
       "147           6.5          3.0           5.2          2.0\n",
       "148           6.2          3.4           5.4          2.3\n",
       "149           5.9          3.0           5.1          1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "csv_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "col_names = ['Sepal_Length','Sepal_Width','Petal_Length','Petal_Width','Class']\n",
    "df =  pd.read_csv(csv_url, names = col_names)\n",
    "features = df[['Sepal_Length', 'Sepal_Width','Petal_Length','Petal_Width']]\n",
    "targets = df['Class']\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Wyznaczamy macierz kowariancji (czyli zależność pomiędzy poszczególnymi kolumnami):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.68569351, -0.03926846,  1.27368233,  0.5169038 ],\n",
       "       [-0.03926846,  0.18800403, -0.32171275, -0.11798121],\n",
       "       [ 1.27368233, -0.32171275,  3.11317942,  1.29638747],\n",
       "       [ 0.5169038 , -0.11798121,  1.29638747,  0.58241432]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macierz_kowariancji = np.cov(features.T)\n",
    "macierz_kowariancji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kowariancja mierzy, jak bardzo dwie zmienne są ze sobą powiązane i jak bardzo jedna zmienna wpływa na wartość drugiej zmiennej.\n",
    "Macierz kowariancji zawiera informacje o kowariancjach pomiędzy wszystkimi parami zmiennych w zbiorze danych.\n",
    "\n",
    "Kowariancja, cov⁡(X,Y) – liczba określająca odchylenie elementów od sytuacji idealnej, w której występuje zależność liniowa. Zależność tę określa się między zmiennymi losowymi X i Y.\n",
    "\n",
    "![](../img/2023-03-27-09-49-33.png)\n",
    "\n",
    "W macierzy kowariancji:\n",
    "- elementy po przekątnej odpowiadają wariancji każdej zmiennej, czyli mierzą jak bardzo wartości zmieniają się wokół swojego średniego poziomu. \n",
    "- Elementy poza przekątną to kowariancje pomiędzy parami zmiennych, czyli mierzą w jaki sposób zmiany jednej zmiennej są skorelowane ze zmianami drugiej zmiennej."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Wyznaczamy wartości i wektory własne macierzy kowariancji:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.22484077, 0.24224357, 0.07852391, 0.02368303]),\n",
       " array([[ 0.36158968, -0.65653988, -0.58099728,  0.31725455],\n",
       "        [-0.08226889, -0.72971237,  0.59641809, -0.32409435],\n",
       "        [ 0.85657211,  0.1757674 ,  0.07252408, -0.47971899],\n",
       "        [ 0.35884393,  0.07470647,  0.54906091,  0.75112056]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wartosci_wlasne, wektory_wlasne = np.linalg.eig(macierz_kowariancji)\n",
    "wartosci_wlasne, wektory_wlasne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Sortujemy wartości własne malejąco. \n",
    "Te, które mają większe wartości, odpowiadają kierunkom w przestrzeni, w których zmienność danych jest większa (a więc zawierają najwięcej informacji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.22484077, 0.24224357, 0.07852391, 0.02368303]),\n",
       " array([[ 0.36158968, -0.65653988, -0.58099728,  0.31725455],\n",
       "        [-0.08226889, -0.72971237,  0.59641809, -0.32409435],\n",
       "        [ 0.85657211,  0.1757674 ,  0.07252408, -0.47971899],\n",
       "        [ 0.35884393,  0.07470647,  0.54906091,  0.75112056]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indeksy_sort = wartosci_wlasne.argsort()[::-1] #argsort zwraca numery indexow od najmniejszej wartosci, [::-1] odwraca kolejnosc\n",
    "wartosci_wlasne_posortowane = wartosci_wlasne[indeksy_sort]\n",
    "wektory_wlasne_posortowane = wektory_wlasne[:, indeksy_sort]\n",
    "wartosci_wlasne_posortowane, wektory_wlasne_posortowane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Wykorzystujemy wektory własne do redukcji wymiarowości. \n",
    "- Możemy wybrać kilka największych wartości własnych i odpowiadające im wektory własne, a następnie pomnożyć macierz danych przez te wektory własne. \n",
    "- Otrzymamy w ten sposób nową macierz danych z mniejszą ilością wymiarów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.827136</td>\n",
       "      <td>-5.641331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.795952</td>\n",
       "      <td>-5.145167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.621524</td>\n",
       "      <td>-5.177378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.764906</td>\n",
       "      <td>-5.003599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.782750</td>\n",
       "      <td>-5.648648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>7.455360</td>\n",
       "      <td>-5.502139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>7.037007</td>\n",
       "      <td>-4.939703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>7.275389</td>\n",
       "      <td>-5.393243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>7.412972</td>\n",
       "      <td>-5.430600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>6.901009</td>\n",
       "      <td>-5.031837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1\n",
       "0    2.827136 -5.641331\n",
       "1    2.795952 -5.145167\n",
       "2    2.621524 -5.177378\n",
       "3    2.764906 -5.003599\n",
       "4    2.782750 -5.648648\n",
       "..        ...       ...\n",
       "145  7.455360 -5.502139\n",
       "146  7.037007 -4.939703\n",
       "147  7.275389 -5.393243\n",
       "148  7.412972 -5.430600\n",
       "149  6.901009 -5.031837\n",
       "\n",
       "[150 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "najwieksze_wartosci_wlasne = wartosci_wlasne_posortowane[:2]\n",
    "najwieksze_wektory_wlasne = wektory_wlasne_posortowane[:, :2]\n",
    "new_features = features.dot(najwieksze_wektory_wlasne)\n",
    "new_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W ten sposób uzyskujemy nową macierz danych, która jest mniejsza wymiarowo, a więc łatwiejsza do przetworzenia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Przykład szybkiej nauki regresjii logistycznej dla zewryfikowania, czy dane po redukcji wymiarowości dalej mają wartość opisującą"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target vs prediction:  ('Iris-setosa', 'Iris-setosa')\n",
      "target vs prediction:  ('Iris-setosa', 'Iris-setosa')\n",
      "target vs prediction:  ('Iris-setosa', 'Iris-setosa')\n",
      "target vs prediction:  ('Iris-virginica', 'Iris-virginica')\n",
      "target vs prediction:  ('Iris-versicolor', 'Iris-versicolor')\n",
      "target vs prediction:  ('Iris-virginica', 'Iris-virginica')\n",
      "target vs prediction:  ('Iris-versicolor', 'Iris-versicolor')\n",
      "target vs prediction:  ('Iris-versicolor', 'Iris-versicolor')\n",
      "target vs prediction:  ('Iris-virginica', 'Iris-virginica')\n",
      "target vs prediction:  ('Iris-setosa', 'Iris-setosa')\n",
      "target vs prediction:  ('Iris-virginica', 'Iris-virginica')\n",
      "target vs prediction:  ('Iris-setosa', 'Iris-setosa')\n",
      "\n",
      "Dokładność modelu po redukcji wymiarów: 0.9666666666666667\n",
      "Dokładność modelu z oryginalnych danych: 1.0\n",
      "\n",
      "Uwaga - wyniki modeli sa uzaleznione od random-state. \n",
      "Dla niektórych wynik po redukcji będzie jednakowy albo nawet lepszy niż przed!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Ten warning informuje, że dobrze byłoby normalizować dane dla osiągnięcia lepszych wyników. Na potrzeby prezentacji przykładu możemy to zignorować\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from warnings import simplefilter\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "# Podział na zbiór treningowy i testowy\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_features, targets, test_size=0.2, random_state=101)\n",
    "\n",
    "# Trenowanie modelu\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Ocena dokładności modelu\n",
    "y_pred = model.predict(X_test)\n",
    "for id, row in enumerate(zip(y_test, y_pred)):\n",
    "    print('target vs prediction: ', row)\n",
    "    if id>10: break\n",
    "\n",
    "score = model.score(X_test, y_test)\n",
    "print(\"\\nDokładność modelu po redukcji wymiarów:\", score)\n",
    "\n",
    "# # DLA PORÓWNANIA MODEL WYTRENOWANY NA ORYGINALNYCH DANYCH (BEZ REDUKCJI WYMIARÓW):\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.2, random_state=101)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "score = model.score(X_test, y_test)\n",
    "print(\"Dokładność modelu z oryginalnych danych:\", score)\n",
    "\n",
    "print(\"\\nUwaga - wyniki modeli sa uzaleznione od random-state. \\nDla niektórych wynik po redukcji będzie jednakowy albo nawet lepszy niż przed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA z pakietem sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.67919741 -0.03258618  1.27066452  0.5321852 ]\n",
      " [-0.03258618  0.18113034 -0.31863564 -0.13363564]\n",
      " [ 1.27066452 -0.31863564  3.11934547  1.28541527]\n",
      " [ 0.5321852  -0.13363564  1.28541527  0.58961806]]\n",
      "[[ 0.36158968 -0.08226889  0.85657211  0.35884393]\n",
      " [ 0.65653988  0.72971237 -0.1757674  -0.07470647]]\n",
      "[4.22484077 0.24224357]\n",
      "\n",
      "wartośc objaśniająca dla każdej z kolumn: [0.92461621 0.05301557]\n",
      "Jak widać 1 kolumna ma 92% wartości objaśniające, druga 5% \n",
      "Razem mają ~97% tak odrzucajac 2 kolumny (połowę) tracimy tylko 3% informacji\n",
      "\n",
      "Fragment danych po redukcji wymiarów:\n",
      " [[-2.68420713  0.32660731]\n",
      " [-2.71539062 -0.16955685]\n",
      " [-2.88981954 -0.13734561]\n",
      " [-2.7464372  -0.31112432]\n",
      " [-2.72859298  0.33392456]\n",
      " [-2.27989736  0.74778271]\n",
      " [-2.82089068 -0.08210451]\n",
      " [-2.62648199  0.17040535]\n",
      " [-2.88795857 -0.57079803]\n",
      " [-2.67384469 -0.1066917 ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(features)\n",
    "# Wypisanie macierzy kowariancji, wektorów własncyh i wartości własncyh\n",
    "print(f\"{pca.get_covariance()}\\n{pca.components_}\\n{pca.explained_variance_}\")\n",
    "\n",
    "print('\\nwartośc objaśniająca dla każdej z kolumn:', pca.explained_variance_ratio_)\n",
    "print('Jak widać 1 kolumna ma 92% wartości objaśniające, druga 5% \\nRazem mają ~97% tak odrzucajac 2 kolumny (połowę) tracimy tylko 3% informacji')\n",
    "\n",
    "new_features_pca = pca.transform(features)\n",
    "print(\"\\nFragment danych po redukcji wymiarów:\\n\", new_features_pca[:10])\n",
    "# Tranfsormacje można odwrócić z użyciem pca.inverse_transform(new_features_pca), ale część informacji (~3% w tym wypadku) jest tracona\n",
    "# pca.inverse_transform(new_features_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macierz kowariancji:\n",
      "Wyznaczona przez: np.cov(features.T)\n",
      " [[ 0.68569351 -0.03926846  1.27368233  0.5169038 ]\n",
      " [-0.03926846  0.18800403 -0.32171275 -0.11798121]\n",
      " [ 1.27368233 -0.32171275  3.11317942  1.29638747]\n",
      " [ 0.5169038  -0.11798121  1.29638747  0.58241432]]\n",
      "Wyciągnięte z PCA przez: pca.get_covariance()\n",
      " [[ 0.67919741 -0.03258618  1.27066452  0.5321852 ]\n",
      " [-0.03258618  0.18113034 -0.31863564 -0.13363564]\n",
      " [ 1.27066452 -0.31863564  3.11934547  1.28541527]\n",
      " [ 0.5321852  -0.13363564  1.28541527  0.58961806]]\n",
      "\n",
      "Wektory własne:\n",
      "Wyznaczona przez: np.linalg.eig(macierz_kowariancji)\n",
      " [[ 0.36158968 -0.65653988 -0.58099728  0.31725455]\n",
      " [-0.08226889 -0.72971237  0.59641809 -0.32409435]\n",
      " [ 0.85657211  0.1757674   0.07252408 -0.47971899]\n",
      " [ 0.35884393  0.07470647  0.54906091  0.75112056]]\n",
      "Wyciągnięte z PCA przez: pca.components_\n",
      " [[ 0.36158968 -0.08226889  0.85657211  0.35884393]\n",
      " [ 0.65653988  0.72971237 -0.1757674  -0.07470647]]\n"
     ]
    }
   ],
   "source": [
    "# porównanie wyznaczonych wartości z poprzednio wygenerowanymi\n",
    "print(\"Macierz kowariancji:\")\n",
    "print('Wyznaczona przez: np.cov(features.T)\\n', macierz_kowariancji)\n",
    "print('Wyciągnięte z PCA przez: pca.get_covariance()\\n', pca.get_covariance())\n",
    "\n",
    "print(\"\\nWektory własne:\")\n",
    "print('Wyznaczona przez: np.linalg.eig(macierz_kowariancji)\\n', wektory_wlasne)\n",
    "print('Wyciągnięte z PCA przez: pca.components_\\n', pca.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wartości własne:\n",
      "Wyznaczona przez: np.linalg.eig(macierz_kowariancji)\n",
      " [4.22484077 0.24224357 0.07852391 0.02368303]\n",
      "Wyciągnięte z PCA przez: pca.explained_variance_\n",
      " [4.22484077 0.24224357]\n",
      "\n",
      "Dane po redukcji wymiarów:\n",
      "Wyznaczona przez: features.dot(najwieksze_wektory_wlasne\n",
      "           0         1\n",
      "0  2.827136 -5.641331\n",
      "1  2.795952 -5.145167\n",
      "2  2.621524 -5.177378\n",
      "3  2.764906 -5.003599\n",
      "4  2.782750 -5.648648\n",
      "Wyznaczona przez PCA: pca.transform(features)\n",
      " [[-2.68420713  0.32660731]\n",
      " [-2.71539062 -0.16955685]\n",
      " [-2.88981954 -0.13734561]\n",
      " [-2.7464372  -0.31112432]\n",
      " [-2.72859298  0.33392456]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nWartości własne:\")\n",
    "print('Wyznaczona przez: np.linalg.eig(macierz_kowariancji)\\n', wartosci_wlasne)\n",
    "print('Wyciągnięte z PCA przez: pca.explained_variance_\\n', pca.explained_variance_)\n",
    "\n",
    "print(\"\\nDane po redukcji wymiarów:\")\n",
    "print('Wyznaczona przez: features.dot(najwieksze_wektory_wlasne\\n', new_features[:5])\n",
    "print('Wyznaczona przez PCA: pca.transform(features)\\n', new_features_pca[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a42ccb73e7d9bfdf27e036f1d2b8b681e55fc0743cc5586bc2474d4a60f4b886"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
